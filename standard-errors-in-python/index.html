<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Standard Errors in Python | Vincent Grégoire</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<link rel="canonical" href="http://www.vincentgregoire.com/standard-errors-in-python/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'left', // Change this to 'center' to center equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><meta name="author" content="Vincent Grégoire">
<meta property="og:site_name" content="Vincent Grégoire">
<meta property="og:title" content="Standard Errors in Python">
<meta property="og:url" content="http://www.vincentgregoire.com/standard-errors-in-python/">
<meta property="og:description" content="Estimating standard errors in Python¶Prepared by Vincent Grégoire, Department of Finance, The University of Melbourne.
You can download the latest version as a Jupyter (IPython) notebook at https://gi">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-03-21T07:07:17+11:00">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://www.vincentgregoire.com/">

                <span id="blog-title">Vincent Grégoire</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../">Home</a>
                </li>
<li>
<a href="../research/">Research</a>
                </li>
<li>
<a href="../CV%20Gregoire.pdf">CV</a>
            </li>
<li class="dropdown">
<a href="#" class="dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Code <b class="caret"></b></a>
            <ul class="dropdown-menu">
<li class="active">
<a href=".">Standard errors in Python <span class="sr-only">(active)</span></a>
                    </li>
<li>
<a href="../python-bootcamp/">Python bootcamp</a>
            </li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.ipynb" id="sourcelink">Source</a>
    </li>

                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Standard Errors in Python</a></h1>

        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Estimating-standard-errors-in-Python">Estimating standard errors in Python<a class="anchor-link" href="#Estimating-standard-errors-in-Python">¶</a>
</h2>
<p>Prepared by <a href="http://www.vincentgregoire.com">Vincent Grégoire</a>, Department of Finance, The University of Melbourne.</p>
<p>You can download the latest version as a Jupyter (IPython) notebook at <a href="https://github.com/vgreg/python-se">https://github.com/vgreg/python-se</a>. Last update: Dec. 6 2016.</p>
<p><strong>Contact</strong>: <a href="mailto:vincent.gregoire@unimelb.edu.au">vincent.gregoire@unimelb.edu.au</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A common problem faced by financial economists when transitioning to Python is the <em>apparent</em> inability to easily do things that we have built-in functions for in either Stata, SAS or R. This page aims to alleviate this pain by providing code samples replicating <em>most</em> of the methods discussed on <a href="http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/se_programming.htm">Mitchell A. Petersen's standard errors programming advice page</a>, and more.</p>
<p>This page is a perpetual work in progress, and I'm sure there are probably better/cleaner/faster/more efficient ways to do things, please email me if you have any comments or suggestions. I use Python 2.7, so while most of these examples should work without too much modifications in Python 3, I have not tested them.</p>
<p>The four main modules that serve as the basis for data analysis in Python are <a href="http://pandas.pydata.org">pandas</a>, <a href="http://statsmodels.sourceforge.net">statsmodel</a>, <a href="http://www.numpy.org/">numpy</a> and <a href="https://www.scipy.org/scipylib/index.html">scipy</a>.</p>
<p>Most of these examples rely on on the covariance adjustments of the <code>fit()</code> function for OLS regressions in statsmodels. Unfortunately, the documentation is quite sparse, but some information can be gathered from the <a href="http://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.RegressionResults.get_robustcov_results.html">documentation for <code>get_robustcov_results()</code></a>.</p>
<p>Special thanks to Charles Martineau for providing some of the examples.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.stats.sandwich_covariance</span> <span class="kn">as</span> <span class="nn">sw</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to have a basis for comparison, we'll use Petersen's <a href="http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.txt">sample dataset</a> and compare our results with those <a href="http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.htm">reported on his page</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">urllib</span> <span class="kn">import</span> <span class="n">urlopen</span>

<span class="n">filehandle</span> <span class="o">=</span> <span class="n">urlopen</span><span class="p">(</span><span class="s1">'http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.txt'</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">filehandle</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">'firmid'</span><span class="p">,</span><span class="s1">'year'</span><span class="p">,</span><span class="s1">'x'</span><span class="p">,</span><span class="s1">'y'</span><span class="p">],</span>
                   <span class="n">delim_whitespace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[2]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
<thead><tr style="text-align: right;">
<th></th>
      <th>firmid</th>
      <th>year</th>
      <th>x</th>
      <th>y</th>
    </tr></thead>
<tbody>
<tr>
<th>0</th>
      <td>1</td>
      <td>1</td>
      <td>-1.113973</td>
      <td>2.251535</td>
    </tr>
<tr>
<th>1</th>
      <td>1</td>
      <td>2</td>
      <td>-0.080854</td>
      <td>1.242346</td>
    </tr>
<tr>
<th>2</th>
      <td>1</td>
      <td>3</td>
      <td>-0.237607</td>
      <td>-1.426376</td>
    </tr>
<tr>
<th>3</th>
      <td>1</td>
      <td>4</td>
      <td>-0.152486</td>
      <td>-1.109394</td>
    </tr>
<tr>
<th>4</th>
      <td>1</td>
      <td>5</td>
      <td>-0.001426</td>
      <td>0.914686</td>
    </tr>
<tr>
<th>5</th>
      <td>1</td>
      <td>6</td>
      <td>-1.212737</td>
      <td>-1.424686</td>
    </tr>
<tr>
<th>6</th>
      <td>1</td>
      <td>7</td>
      <td>-0.127273</td>
      <td>0.758945</td>
    </tr>
<tr>
<th>7</th>
      <td>1</td>
      <td>8</td>
      <td>-1.433539</td>
      <td>0.929652</td>
    </tr>
<tr>
<th>8</th>
      <td>1</td>
      <td>9</td>
      <td>-0.242196</td>
      <td>1.056465</td>
    </tr>
<tr>
<th>9</th>
      <td>1</td>
      <td>10</td>
      <td>0.460922</td>
      <td>3.308434</td>
    </tr>
<tr>
<th>10</th>
      <td>2</td>
      <td>1</td>
      <td>-0.550791</td>
      <td>-2.545477</td>
    </tr>
<tr>
<th>11</th>
      <td>2</td>
      <td>2</td>
      <td>-1.287685</td>
      <td>-3.021920</td>
    </tr>
<tr>
<th>12</th>
      <td>2</td>
      <td>3</td>
      <td>-0.220503</td>
      <td>-1.003296</td>
    </tr>
<tr>
<th>13</th>
      <td>2</td>
      <td>4</td>
      <td>0.814318</td>
      <td>-0.118388</td>
    </tr>
<tr>
<th>14</th>
      <td>2</td>
      <td>5</td>
      <td>-0.046372</td>
      <td>-1.279670</td>
    </tr>
<tr>
<th>15</th>
      <td>2</td>
      <td>6</td>
      <td>0.622044</td>
      <td>-3.539696</td>
    </tr>
<tr>
<th>16</th>
      <td>2</td>
      <td>7</td>
      <td>-0.653009</td>
      <td>-2.235361</td>
    </tr>
<tr>
<th>17</th>
      <td>2</td>
      <td>8</td>
      <td>0.029411</td>
      <td>-2.552972</td>
    </tr>
<tr>
<th>18</th>
      <td>2</td>
      <td>9</td>
      <td>-0.529747</td>
      <td>-2.697836</td>
    </tr>
<tr>
<th>19</th>
      <td>2</td>
      <td>10</td>
      <td>1.062629</td>
      <td>-0.263351</td>
    </tr>
<tr>
<th>20</th>
      <td>3</td>
      <td>1</td>
      <td>-1.068723</td>
      <td>1.526512</td>
    </tr>
<tr>
<th>21</th>
      <td>3</td>
      <td>2</td>
      <td>-1.487991</td>
      <td>-1.168439</td>
    </tr>
<tr>
<th>22</th>
      <td>3</td>
      <td>3</td>
      <td>-0.814688</td>
      <td>1.043587</td>
    </tr>
<tr>
<th>23</th>
      <td>3</td>
      <td>4</td>
      <td>-0.233863</td>
      <td>-0.119772</td>
    </tr>
<tr>
<th>24</th>
      <td>3</td>
      <td>5</td>
      <td>0.152062</td>
      <td>0.808258</td>
    </tr>
<tr>
<th>25</th>
      <td>3</td>
      <td>6</td>
      <td>-0.719077</td>
      <td>0.406351</td>
    </tr>
<tr>
<th>26</th>
      <td>3</td>
      <td>7</td>
      <td>-0.789831</td>
      <td>0.176693</td>
    </tr>
<tr>
<th>27</th>
      <td>3</td>
      <td>8</td>
      <td>0.234270</td>
      <td>-0.055562</td>
    </tr>
<tr>
<th>28</th>
      <td>3</td>
      <td>9</td>
      <td>-1.761113</td>
      <td>2.518384</td>
    </tr>
<tr>
<th>29</th>
      <td>3</td>
      <td>10</td>
      <td>-0.327372</td>
      <td>-0.783275</td>
    </tr>
<tr>
<th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
<tr>
<th>4970</th>
      <td>498</td>
      <td>1</td>
      <td>0.937313</td>
      <td>2.435911</td>
    </tr>
<tr>
<th>4971</th>
      <td>498</td>
      <td>2</td>
      <td>-0.433560</td>
      <td>0.137374</td>
    </tr>
<tr>
<th>4972</th>
      <td>498</td>
      <td>3</td>
      <td>1.249027</td>
      <td>-0.736823</td>
    </tr>
<tr>
<th>4973</th>
      <td>498</td>
      <td>4</td>
      <td>0.536620</td>
      <td>0.590931</td>
    </tr>
<tr>
<th>4974</th>
      <td>498</td>
      <td>5</td>
      <td>2.481492</td>
      <td>7.002803</td>
    </tr>
<tr>
<th>4975</th>
      <td>498</td>
      <td>6</td>
      <td>1.458367</td>
      <td>2.051867</td>
    </tr>
<tr>
<th>4976</th>
      <td>498</td>
      <td>7</td>
      <td>1.267130</td>
      <td>2.335333</td>
    </tr>
<tr>
<th>4977</th>
      <td>498</td>
      <td>8</td>
      <td>1.979471</td>
      <td>4.102230</td>
    </tr>
<tr>
<th>4978</th>
      <td>498</td>
      <td>9</td>
      <td>1.466995</td>
      <td>4.206719</td>
    </tr>
<tr>
<th>4979</th>
      <td>498</td>
      <td>10</td>
      <td>0.981465</td>
      <td>1.769253</td>
    </tr>
<tr>
<th>4980</th>
      <td>499</td>
      <td>1</td>
      <td>0.515411</td>
      <td>-1.192308</td>
    </tr>
<tr>
<th>4981</th>
      <td>499</td>
      <td>2</td>
      <td>-0.082360</td>
      <td>0.492265</td>
    </tr>
<tr>
<th>4982</th>
      <td>499</td>
      <td>3</td>
      <td>0.450559</td>
      <td>-1.388515</td>
    </tr>
<tr>
<th>4983</th>
      <td>499</td>
      <td>4</td>
      <td>0.347505</td>
      <td>0.794183</td>
    </tr>
<tr>
<th>4984</th>
      <td>499</td>
      <td>5</td>
      <td>-0.760993</td>
      <td>-1.084250</td>
    </tr>
<tr>
<th>4985</th>
      <td>499</td>
      <td>6</td>
      <td>-0.891608</td>
      <td>-3.299844</td>
    </tr>
<tr>
<th>4986</th>
      <td>499</td>
      <td>7</td>
      <td>-0.603919</td>
      <td>-2.204624</td>
    </tr>
<tr>
<th>4987</th>
      <td>499</td>
      <td>8</td>
      <td>0.717169</td>
      <td>1.272819</td>
    </tr>
<tr>
<th>4988</th>
      <td>499</td>
      <td>9</td>
      <td>0.426611</td>
      <td>-2.184453</td>
    </tr>
<tr>
<th>4989</th>
      <td>499</td>
      <td>10</td>
      <td>0.662455</td>
      <td>-1.470384</td>
    </tr>
<tr>
<th>4990</th>
      <td>500</td>
      <td>1</td>
      <td>0.028352</td>
      <td>1.502491</td>
    </tr>
<tr>
<th>4991</th>
      <td>500</td>
      <td>2</td>
      <td>-0.527109</td>
      <td>-0.595065</td>
    </tr>
<tr>
<th>4992</th>
      <td>500</td>
      <td>3</td>
      <td>-0.418416</td>
      <td>2.122376</td>
    </tr>
<tr>
<th>4993</th>
      <td>500</td>
      <td>4</td>
      <td>1.557888</td>
      <td>0.603051</td>
    </tr>
<tr>
<th>4994</th>
      <td>500</td>
      <td>5</td>
      <td>-0.187499</td>
      <td>-0.818244</td>
    </tr>
<tr>
<th>4995</th>
      <td>500</td>
      <td>6</td>
      <td>-0.077057</td>
      <td>3.720502</td>
    </tr>
<tr>
<th>4996</th>
      <td>500</td>
      <td>7</td>
      <td>0.218847</td>
      <td>0.559121</td>
    </tr>
<tr>
<th>4997</th>
      <td>500</td>
      <td>8</td>
      <td>-0.155530</td>
      <td>-3.766785</td>
    </tr>
<tr>
<th>4998</th>
      <td>500</td>
      <td>9</td>
      <td>-0.040172</td>
      <td>0.903354</td>
    </tr>
<tr>
<th>4999</th>
      <td>500</td>
      <td>10</td>
      <td>-0.001172</td>
      <td>-0.529761</td>
    </tr>
</tbody>
</table>
<p>5000 rows × 4 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="OLS-and-statsmodels">OLS and statsmodels<a class="anchor-link" href="#OLS-and-statsmodels">¶</a>
</h2>
<h3 id="OLS-Coefficients-and-Standard-Errors">OLS Coefficients and Standard Errors<a class="anchor-link" href="#OLS-Coefficients-and-Standard-Errors">¶</a>
</h3>
<p>There are many, many ways to run a simple OLS regression in Python. This example uses the formula API from statmodels that lets you use R-style formulas. The <code>use_t</code> parameter tells statsmodels to use $t$-statistics to compute the $p$-values. For more information on formula construction, see the <a href="http://patsy.readthedocs.org/en/latest/">patsy documentation</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ols</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[3]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
<th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.208</td> 
</tr>
<tr>
<th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.208</td> 
</tr>
<tr>
<th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1311.</td> 
</tr>
<tr>
<th>Date:</th>             <td>Tue, 06 Dec 2016</td> <th>  Prob (F-statistic):</th> <td>4.25e-255</td>
</tr>
<tr>
<th>Time:</th>                 <td>16:31:45</td>     <th>  Log-Likelihood:    </th> <td> -10573.</td> 
</tr>
<tr>
<th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>2.115e+04</td>
</tr>
<tr>
<th>Df Residuals:</th>          <td>  4998</td>      <th>  BIC:               </th> <td>2.116e+04</td>
</tr>
<tr>
<th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
<th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
<td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
<th>Intercept</th> <td>    0.0297</td> <td>    0.028</td> <td>    1.047</td> <td> 0.295</td> <td>   -0.026     0.085</td>
</tr>
<tr>
<th>x</th>         <td>    1.0348</td> <td>    0.029</td> <td>   36.204</td> <td> 0.000</td> <td>    0.979     1.091</td>
</tr>
</table>
<table class="simpletable">
<tr>
<th>Omnibus:</th>       <td> 4.912</td> <th>  Durbin-Watson:     </th> <td>   1.096</td>
</tr>
<tr>
<th>Prob(Omnibus):</th> <td> 0.086</td> <th>  Jarque-Bera (JB):  </th> <td>   4.862</td>
</tr>
<tr>
<th>Skew:</th>          <td> 0.070</td> <th>  Prob(JB):          </th> <td>  0.0880</td>
</tr>
<tr>
<th>Kurtosis:</th>      <td> 3.063</td> <th>  Cond. No.          </th> <td>    1.01</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="OLS-Coefficients-and-White-Standard-Errors">OLS Coefficients and White Standard Errors<a class="anchor-link" href="#OLS-Coefficients-and-White-Standard-Errors">¶</a>
</h3>
<p>Adding heteroscedasticity-consistent standard errors is not much harder. The <code>cov_type</code> parameter can take many values, for heteroscedasticity-consistent standard errors different implementations take the values <code>HC0</code> (the original White estimator) to <code>HC3</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">robust_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">'HC1'</span><span class="p">,</span> <span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">robust_ols</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[4]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
<th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.208</td> 
</tr>
<tr>
<th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.208</td> 
</tr>
<tr>
<th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1328.</td> 
</tr>
<tr>
<th>Date:</th>             <td>Tue, 06 Dec 2016</td> <th>  Prob (F-statistic):</th> <td>4.29e-258</td>
</tr>
<tr>
<th>Time:</th>                 <td>16:31:45</td>     <th>  Log-Likelihood:    </th> <td> -10573.</td> 
</tr>
<tr>
<th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>2.115e+04</td>
</tr>
<tr>
<th>Df Residuals:</th>          <td>  4998</td>      <th>  BIC:               </th> <td>2.116e+04</td>
</tr>
<tr>
<th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
<th>Covariance Type:</th>         <td>HC1</td>       <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
<td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
<th>Intercept</th> <td>    0.0297</td> <td>    0.028</td> <td>    1.047</td> <td> 0.295</td> <td>   -0.026     0.085</td>
</tr>
<tr>
<th>x</th>         <td>    1.0348</td> <td>    0.028</td> <td>   36.444</td> <td> 0.000</td> <td>    0.979     1.091</td>
</tr>
</table>
<table class="simpletable">
<tr>
<th>Omnibus:</th>       <td> 4.912</td> <th>  Durbin-Watson:     </th> <td>   1.096</td>
</tr>
<tr>
<th>Prob(Omnibus):</th> <td> 0.086</td> <th>  Jarque-Bera (JB):  </th> <td>   4.862</td>
</tr>
<tr>
<th>Skew:</th>          <td> 0.070</td> <th>  Prob(JB):          </th> <td>  0.0880</td>
</tr>
<tr>
<th>Kurtosis:</th>      <td> 3.063</td> <th>  Cond. No.          </th> <td>    1.01</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="OLS-Coefficients-and-Standard-Errors-Clustered-by-Firm-or-Year">OLS Coefficients and Standard Errors Clustered by Firm or Year<a class="anchor-link" href="#OLS-Coefficients-and-Standard-Errors-Clustered-by-Firm-or-Year">¶</a>
</h3>
<p>Clustering can also be acheived by passing <code>cluster</code> to the <code>cov_type</code> parameter. You also need to give an additional parameter <code>cov_kwds</code>, which indicates which group to cluster on. The parameters takes an arrays of labels, which can be the columns of a pandas DataFrame as in this example.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">cluster_firm_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">'cluster'</span><span class="p">,</span>
                                                        <span class="n">cov_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">'groups'</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">'firmid'</span><span class="p">]},</span>
                                                        <span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">cluster_firm_ols</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[5]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
<th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.208</td> 
</tr>
<tr>
<th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.208</td> 
</tr>
<tr>
<th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   418.3</td> 
</tr>
<tr>
<th>Date:</th>             <td>Tue, 06 Dec 2016</td> <th>  Prob (F-statistic):</th> <td>5.61e-68</td> 
</tr>
<tr>
<th>Time:</th>                 <td>16:31:45</td>     <th>  Log-Likelihood:    </th> <td> -10573.</td> 
</tr>
<tr>
<th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>2.115e+04</td>
</tr>
<tr>
<th>Df Residuals:</th>          <td>  4998</td>      <th>  BIC:               </th> <td>2.116e+04</td>
</tr>
<tr>
<th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
<th>Covariance Type:</th>       <td>cluster</td>     <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
<td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
<th>Intercept</th> <td>    0.0297</td> <td>    0.067</td> <td>    0.443</td> <td> 0.658</td> <td>   -0.102     0.161</td>
</tr>
<tr>
<th>x</th>         <td>    1.0348</td> <td>    0.051</td> <td>   20.453</td> <td> 0.000</td> <td>    0.935     1.134</td>
</tr>
</table>
<table class="simpletable">
<tr>
<th>Omnibus:</th>       <td> 4.912</td> <th>  Durbin-Watson:     </th> <td>   1.096</td>
</tr>
<tr>
<th>Prob(Omnibus):</th> <td> 0.086</td> <th>  Jarque-Bera (JB):  </th> <td>   4.862</td>
</tr>
<tr>
<th>Skew:</th>          <td> 0.070</td> <th>  Prob(JB):          </th> <td>  0.0880</td>
</tr>
<tr>
<th>Kurtosis:</th>      <td> 3.063</td> <th>  Cond. No.          </th> <td>    1.01</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">cluster_year_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">'cluster'</span><span class="p">,</span>
                                                        <span class="n">cov_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">'groups'</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">'year'</span><span class="p">]},</span>
                                                        <span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">cluster_year_ols</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[6]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
<th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.208</td> 
</tr>
<tr>
<th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.208</td> 
</tr>
<tr>
<th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   960.6</td> 
</tr>
<tr>
<th>Date:</th>             <td>Tue, 06 Dec 2016</td> <th>  Prob (F-statistic):</th> <td>1.86e-10</td> 
</tr>
<tr>
<th>Time:</th>                 <td>16:31:45</td>     <th>  Log-Likelihood:    </th> <td> -10573.</td> 
</tr>
<tr>
<th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>2.115e+04</td>
</tr>
<tr>
<th>Df Residuals:</th>          <td>  4998</td>      <th>  BIC:               </th> <td>2.116e+04</td>
</tr>
<tr>
<th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
<th>Covariance Type:</th>       <td>cluster</td>     <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
<td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
<th>Intercept</th> <td>    0.0297</td> <td>    0.023</td> <td>    1.269</td> <td> 0.236</td> <td>   -0.023     0.083</td>
</tr>
<tr>
<th>x</th>         <td>    1.0348</td> <td>    0.033</td> <td>   30.993</td> <td> 0.000</td> <td>    0.959     1.110</td>
</tr>
</table>
<table class="simpletable">
<tr>
<th>Omnibus:</th>       <td> 4.912</td> <th>  Durbin-Watson:     </th> <td>   1.096</td>
</tr>
<tr>
<th>Prob(Omnibus):</th> <td> 0.086</td> <th>  Jarque-Bera (JB):  </th> <td>   4.862</td>
</tr>
<tr>
<th>Skew:</th>          <td> 0.070</td> <th>  Prob(JB):          </th> <td>  0.0880</td>
</tr>
<tr>
<th>Kurtosis:</th>      <td> 3.063</td> <th>  Cond. No.          </th> <td>    1.01</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="OLS-Coefficients-and-Standard-Errors-Clustered-by-Firm-and-Year">OLS Coefficients and Standard Errors Clustered by Firm and Year<a class="anchor-link" href="#OLS-Coefficients-and-Standard-Errors-Clustered-by-Firm-and-Year">¶</a>
</h3>
<p>Clustering along two dimensions is as easy as clustering along one dimension, all you have to do is pass an array of two colums as the group. The only caveat is that the group cannot be a <code>pandas</code> <code>DataFrame</code> (while it can be a <code>Series</code>), you need to encapsulate it in <code>numpy.array()</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">cluster_2ways_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">'cluster'</span><span class="p">,</span>
                                                         <span class="n">cov_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">'groups'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">'firmid'</span><span class="p">,</span> <span class="s1">'year'</span><span class="p">]])},</span>
                                                         <span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">cluster_2ways_ols</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[7]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
<th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.208</td> 
</tr>
<tr>
<th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.208</td> 
</tr>
<tr>
<th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   373.3</td> 
</tr>
<tr>
<th>Date:</th>             <td>Tue, 06 Dec 2016</td> <th>  Prob (F-statistic):</th> <td>1.23e-08</td> 
</tr>
<tr>
<th>Time:</th>                 <td>16:31:45</td>     <th>  Log-Likelihood:    </th> <td> -10573.</td> 
</tr>
<tr>
<th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>2.115e+04</td>
</tr>
<tr>
<th>Df Residuals:</th>          <td>  4998</td>      <th>  BIC:               </th> <td>2.116e+04</td>
</tr>
<tr>
<th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
<th>Covariance Type:</th>       <td>cluster</td>     <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
<td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
<th>Intercept</th> <td>    0.0297</td> <td>    0.065</td> <td>    0.456</td> <td> 0.659</td> <td>   -0.118     0.177</td>
</tr>
<tr>
<th>x</th>         <td>    1.0348</td> <td>    0.054</td> <td>   19.322</td> <td> 0.000</td> <td>    0.914     1.156</td>
</tr>
</table>
<table class="simpletable">
<tr>
<th>Omnibus:</th>       <td> 4.912</td> <th>  Durbin-Watson:     </th> <td>   1.096</td>
</tr>
<tr>
<th>Prob(Omnibus):</th> <td> 0.086</td> <th>  Jarque-Bera (JB):  </th> <td>   4.862</td>
</tr>
<tr>
<th>Skew:</th>          <td> 0.070</td> <th>  Prob(JB):          </th> <td>  0.0880</td>
</tr>
<tr>
<th>Kurtosis:</th>      <td> 3.063</td> <th>  Cond. No.          </th> <td>    1.01</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="OLS-Standard-Errors-Clustering-with-N-dimensions">OLS Standard Errors Clustering with N dimensions<a class="anchor-link" href="#OLS-Standard-Errors-Clustering-with-N-dimensions">¶</a>
</h3>
<p>As far as I know, there is no built-in function for $N$-way clustering in Python when $N&gt;2$. One workaround suggested by my colleague <a href="https://sites.google.com/site/zzhong225/">Zhuo Zhong</a> is to use the <code>rpy2</code> package to link Python with <code>R</code> and estimate the standard errors with the <code>multiwayvcov</code> library. The following example replicates the previous one with 2-way clustering, but can easily be extended to more than 2 groups (just pass more than two groups to the function).</p>
<p>You first need to have <code>R</code> installed. If you are using the Anaconda environment, see <a href="http://conda.pydata.org/docs/r-with-conda.html">http://conda.pydata.org/docs/r-with-conda.html</a>.</p>
<p>To install the required <code>R</code> libraries, you can use the following code:</p>

<pre><code>from rpy2.robjects.packages import importr
utils = importr('utils')
utils.chooseCRANmirror(ind=12)
utils.install_packages('multiwayvcov')
utils.install_packages('lmtest')

</code></pre>
<p>Here is a sample function that lets you retreive coefficient estimates, standard errors, $t$-values and $p$-values.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">rpy2.robjects</span> <span class="kn">import</span> <span class="n">pandas2ri</span>
<span class="kn">import</span> <span class="nn">rpy2.robjects</span> <span class="kn">as</span> <span class="nn">ro</span>

<span class="c1"># Hide warnings (R is quite verbose). Comment out to keep the warnings</span>
<span class="n">ro</span><span class="o">.</span><span class="n">r</span><span class="p">[</span><span class="s1">'options'</span><span class="p">](</span><span class="n">warn</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">pandas2ri</span><span class="o">.</span><span class="n">activate</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># model is a string (R-style regression model)</span>
<span class="c1"># clusters is a list a strings</span>
<span class="c1"># returns a pandas DataFrame</span>
<span class="k">def</span> <span class="nf">multiway_cluster</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">clusters</span><span class="p">):</span>
    <span class="n">rdf</span> <span class="o">=</span> <span class="n">pandas2ri</span><span class="o">.</span><span class="n">py2ri</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="n">ro</span><span class="o">.</span><span class="n">globalenv</span><span class="p">[</span><span class="s1">'rdf'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rdf</span>

    <span class="n">clusters_grp</span> <span class="o">=</span> <span class="s1">' + '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">'rdf$'</span> <span class="o">+</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">])</span>
    <span class="n">reg_command</span> <span class="o">=</span> <span class="s1">'reg &lt;- lm('</span> <span class="o">+</span> <span class="n">model</span> <span class="o">+</span> <span class="s1">', data = rdf)</span><span class="se">\n</span><span class="s1">'</span>
    <span class="n">vcov_command</span> <span class="o">=</span> <span class="s1">'reg$vcov &lt;- cluster.vcov(reg, ~ '</span> <span class="o">+</span> <span class="n">clusters_grp</span> <span class="o">+</span> <span class="s1">')</span><span class="se">\n</span><span class="s1">'</span>
    <span class="n">libraries</span> <span class="o">=</span> <span class="s1">'''</span>
<span class="s1">library(zoo)</span>
<span class="s1">library(multiwayvcov)</span>
<span class="s1">library(lmtest)</span>
<span class="s1">'''</span>
    <span class="n">output</span> <span class="o">=</span> <span class="s1">'''</span>
<span class="s1">result &lt;- coeftest(reg, reg$vcov)</span>
<span class="s1">regnames &lt;- attributes(result)$dimnames[[1]]</span>
<span class="s1">colnames &lt;- attributes(result)$dimnames[[2]]</span>
<span class="s1">'''</span>

    <span class="n">command</span> <span class="o">=</span> <span class="n">libraries</span> <span class="o">+</span> <span class="n">reg_command</span> <span class="o">+</span> <span class="n">vcov_command</span> <span class="o">+</span> <span class="n">output</span>
    <span class="n">ro</span><span class="o">.</span><span class="n">r</span><span class="p">(</span><span class="n">command</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">ro</span><span class="o">.</span><span class="n">r</span><span class="p">(</span><span class="s1">'result'</span><span class="p">))</span>
    <span class="n">res</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">ro</span><span class="o">.</span><span class="n">r</span><span class="p">(</span><span class="s1">'colnames'</span><span class="p">)</span>
    <span class="n">res</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">ro</span><span class="o">.</span><span class="n">r</span><span class="p">(</span><span class="s1">'regnames'</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">res</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">multiway_cluster</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">'y ~ x'</span><span class="p">,</span> <span class="n">clusters</span><span class="o">=</span><span class="p">[</span><span class="s1">'firmid'</span><span class="p">,</span> <span class="s1">'year'</span><span class="p">])</span>

<span class="c1"># Note: R in quite verbose with the warnings, but most of them aren't really warnings.</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>//anaconda/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: 
Attaching package: ‘zoo’


  warnings.warn(x, RRuntimeWarning)
//anaconda/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric


  warnings.warn(x, RRuntimeWarning)
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt output_prompt">Out[10]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
<thead><tr style="text-align: right;">
<th></th>
      <th>Estimate</th>
      <th>Std. Error</th>
      <th>t value</th>
      <th>Pr(&gt;|t|)</th>
    </tr></thead>
<tbody>
<tr>
<th>(Intercept)</th>
      <td>0.029680</td>
      <td>0.065066</td>
      <td>0.456145</td>
      <td>6.483054e-01</td>
    </tr>
<tr>
<th>x</th>
      <td>1.034833</td>
      <td>0.053561</td>
      <td>19.320640</td>
      <td>2.860052e-80</td>
    </tr>
</tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="OLS-Coefficients-and-Standard-Errors-with-Firm-and/or-Year-Fixed-Effects">OLS Coefficients and Standard Errors with Firm and/or Year Fixed Effects<a class="anchor-link" href="#OLS-Coefficients-and-Standard-Errors-with-Firm-and/or-Year-Fixed-Effects">¶</a>
</h3>
<p>One way to add fixed effects is by adding the corresponding dummy variables. Thankfully this is quite easy to do within a formula by using <code>C(var)</code> where <code>var</code> is the label variable.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">firm_fe_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x + C(firmid)'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#firm_fe_ols.summary()  </span>
<span class="c1"># The summary is ommitted because the large number </span>
<span class="c1"># of dummy variables make it unpleasant to look at.</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">year_fe_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x + C(year)'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">year_fe_ols</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[12]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
<th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.209</td> 
</tr>
<tr>
<th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.207</td> 
</tr>
<tr>
<th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   131.6</td> 
</tr>
<tr>
<th>Date:</th>             <td>Tue, 06 Dec 2016</td> <th>  Prob (F-statistic):</th> <td>7.13e-245</td>
</tr>
<tr>
<th>Time:</th>                 <td>16:31:47</td>     <th>  Log-Likelihood:    </th> <td> -10570.</td> 
</tr>
<tr>
<th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>2.116e+04</td>
</tr>
<tr>
<th>Df Residuals:</th>          <td>  4989</td>      <th>  BIC:               </th> <td>2.123e+04</td>
</tr>
<tr>
<th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
<th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
<td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
<th>Intercept</th>     <td>    0.1411</td> <td>    0.090</td> <td>    1.573</td> <td> 0.116</td> <td>   -0.035     0.317</td>
</tr>
<tr>
<th>C(year)[T.2]</th>  <td>   -0.0119</td> <td>    0.127</td> <td>   -0.094</td> <td> 0.925</td> <td>   -0.261     0.237</td>
</tr>
<tr>
<th>C(year)[T.3]</th>  <td>   -0.1453</td> <td>    0.127</td> <td>   -1.145</td> <td> 0.252</td> <td>   -0.394     0.103</td>
</tr>
<tr>
<th>C(year)[T.4]</th>  <td>   -0.2038</td> <td>    0.127</td> <td>   -1.607</td> <td> 0.108</td> <td>   -0.452     0.045</td>
</tr>
<tr>
<th>C(year)[T.5]</th>  <td>   -0.0604</td> <td>    0.127</td> <td>   -0.476</td> <td> 0.634</td> <td>   -0.309     0.188</td>
</tr>
<tr>
<th>C(year)[T.6]</th>  <td>   -0.1312</td> <td>    0.127</td> <td>   -1.034</td> <td> 0.301</td> <td>   -0.380     0.117</td>
</tr>
<tr>
<th>C(year)[T.7]</th>  <td>   -0.1975</td> <td>    0.127</td> <td>   -1.557</td> <td> 0.120</td> <td>   -0.446     0.051</td>
</tr>
<tr>
<th>C(year)[T.8]</th>  <td>   -0.1555</td> <td>    0.127</td> <td>   -1.225</td> <td> 0.220</td> <td>   -0.404     0.093</td>
</tr>
<tr>
<th>C(year)[T.9]</th>  <td>   -0.1535</td> <td>    0.127</td> <td>   -1.210</td> <td> 0.226</td> <td>   -0.402     0.095</td>
</tr>
<tr>
<th>C(year)[T.10]</th> <td>   -0.0556</td> <td>    0.127</td> <td>   -0.438</td> <td> 0.661</td> <td>   -0.304     0.193</td>
</tr>
<tr>
<th>x</th>             <td>    1.0351</td> <td>    0.029</td> <td>   36.160</td> <td> 0.000</td> <td>    0.979     1.091</td>
</tr>
</table>
<table class="simpletable">
<tr>
<th>Omnibus:</th>       <td> 4.804</td> <th>  Durbin-Watson:     </th> <td>   1.096</td>
</tr>
<tr>
<th>Prob(Omnibus):</th> <td> 0.091</td> <th>  Jarque-Bera (JB):  </th> <td>   4.752</td>
</tr>
<tr>
<th>Skew:</th>          <td> 0.069</td> <th>  Prob(JB):          </th> <td>  0.0929</td>
</tr>
<tr>
<th>Kurtosis:</th>      <td> 3.061</td> <th>  Cond. No.          </th> <td>    10.9</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">firm_year_fe_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x + C(firmid) + C(year)'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#firm_year_fe_ols.summary() </span>
<span class="c1"># The summary is ommitted because the large number </span>
<span class="c1"># of dummy variables make it unpleasant to look at.</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fixed-Effects-and-Clustered-Standard-Errors">Fixed Effects and Clustered Standard Errors<a class="anchor-link" href="#Fixed-Effects-and-Clustered-Standard-Errors">¶</a>
</h3>
<p>By combining the previous examples, you can have fixed effects and clustered standard errors at the same time.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">firm_cluster_year_fe_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x + C(year)'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">'cluster'</span><span class="p">,</span>
                                                                          <span class="n">cov_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">'groups'</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">'firmid'</span><span class="p">]},</span>
                                                                          <span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">firm_cluster_year_fe_ols</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[14]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
<th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.209</td> 
</tr>
<tr>
<th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.207</td> 
</tr>
<tr>
<th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   43.23</td> 
</tr>
<tr>
<th>Date:</th>             <td>Tue, 06 Dec 2016</td> <th>  Prob (F-statistic):</th> <td>1.93e-61</td> 
</tr>
<tr>
<th>Time:</th>                 <td>16:31:48</td>     <th>  Log-Likelihood:    </th> <td> -10570.</td> 
</tr>
<tr>
<th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>2.116e+04</td>
</tr>
<tr>
<th>Df Residuals:</th>          <td>  4989</td>      <th>  BIC:               </th> <td>2.123e+04</td>
</tr>
<tr>
<th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
<th>Covariance Type:</th>       <td>cluster</td>     <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
<td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
<th>Intercept</th>     <td>    0.1411</td> <td>    0.089</td> <td>    1.587</td> <td> 0.113</td> <td>   -0.034     0.316</td>
</tr>
<tr>
<th>C(year)[T.2]</th>  <td>   -0.0119</td> <td>    0.086</td> <td>   -0.139</td> <td> 0.890</td> <td>   -0.181     0.157</td>
</tr>
<tr>
<th>C(year)[T.3]</th>  <td>   -0.1453</td> <td>    0.086</td> <td>   -1.690</td> <td> 0.092</td> <td>   -0.314     0.024</td>
</tr>
<tr>
<th>C(year)[T.4]</th>  <td>   -0.2038</td> <td>    0.089</td> <td>   -2.288</td> <td> 0.023</td> <td>   -0.379    -0.029</td>
</tr>
<tr>
<th>C(year)[T.5]</th>  <td>   -0.0604</td> <td>    0.087</td> <td>   -0.697</td> <td> 0.486</td> <td>   -0.231     0.110</td>
</tr>
<tr>
<th>C(year)[T.6]</th>  <td>   -0.1312</td> <td>    0.084</td> <td>   -1.562</td> <td> 0.119</td> <td>   -0.296     0.034</td>
</tr>
<tr>
<th>C(year)[T.7]</th>  <td>   -0.1975</td> <td>    0.087</td> <td>   -2.275</td> <td> 0.023</td> <td>   -0.368    -0.027</td>
</tr>
<tr>
<th>C(year)[T.8]</th>  <td>   -0.1555</td> <td>    0.094</td> <td>   -1.662</td> <td> 0.097</td> <td>   -0.339     0.028</td>
</tr>
<tr>
<th>C(year)[T.9]</th>  <td>   -0.1535</td> <td>    0.088</td> <td>   -1.752</td> <td> 0.080</td> <td>   -0.326     0.019</td>
</tr>
<tr>
<th>C(year)[T.10]</th> <td>   -0.0556</td> <td>    0.088</td> <td>   -0.634</td> <td> 0.526</td> <td>   -0.228     0.117</td>
</tr>
<tr>
<th>x</th>             <td>    1.0351</td> <td>    0.051</td> <td>   20.361</td> <td> 0.000</td> <td>    0.935     1.135</td>
</tr>
</table>
<table class="simpletable">
<tr>
<th>Omnibus:</th>       <td> 4.804</td> <th>  Durbin-Watson:     </th> <td>   1.096</td>
</tr>
<tr>
<th>Prob(Omnibus):</th> <td> 0.091</td> <th>  Jarque-Bera (JB):  </th> <td>   4.752</td>
</tr>
<tr>
<th>Skew:</th>          <td> 0.069</td> <th>  Prob(JB):          </th> <td>  0.0929</td>
</tr>
<tr>
<th>Kurtosis:</th>      <td> 3.061</td> <th>  Cond. No.          </th> <td>    10.9</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fama-MacBeth-Coefficients-and-Standard-Errors">Fama-MacBeth Coefficients and Standard Errors<a class="anchor-link" href="#Fama-MacBeth-Coefficients-and-Standard-Errors">¶</a>
</h3>
<p>There is an undocumented Fama-MacBeth function in pandas. However, it is planned to be deprecated and from my (limited) experience, I was unable to replicate standard errors obtained using other packages. Therefore, the most sensible option to me was to write my own function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">fama_macbeth</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">time_label</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">time_label</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span>
                                                     <span class="n">data</span><span class="o">=</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">())</span>

    <span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">params</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">res</span><span class="p">]</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>

    <span class="n">means</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">params_labels</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">index</span>

    <span class="c1"># The ':' character used by patsy doesn't play well with pandas column names.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="s1">'_INTER_'</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">lags</span> <span class="ow">is</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">means</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'_INTER_'</span><span class="p">,</span><span class="s1">':'</span><span class="p">)]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">x</span> <span class="o">+</span> <span class="s1">' ~ 1'</span><span class="p">,</span>
                                                     <span class="n">data</span><span class="o">=</span><span class="n">p</span><span class="p">[[</span><span class="n">x</span><span class="p">]])</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">means</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'_INTER_'</span><span class="p">,</span><span class="s1">':'</span><span class="p">)]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">x</span> <span class="o">+</span> <span class="s1">' ~ 1'</span><span class="p">,</span>
                                                     <span class="n">data</span><span class="o">=</span><span class="n">p</span><span class="p">[[</span><span class="n">x</span><span class="p">]])</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">'HAC'</span><span class="p">,</span>
                                                                      <span class="n">cov_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">'maxlags'</span><span class="p">:</span> <span class="n">lags</span><span class="p">},</span>
                                                                      <span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">stderrs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">tvalues</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pvalues</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">params_labels</span><span class="p">:</span>
        <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">'Intercept'</span><span class="p">])</span>
        <span class="n">stderrs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">bse</span><span class="p">[</span><span class="s1">'Intercept'</span><span class="p">])</span>
        <span class="n">tvalues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="s1">'Intercept'</span><span class="p">])</span>
        <span class="n">pvalues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">pvalues</span><span class="p">[</span><span class="s1">'Intercept'</span><span class="p">])</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">params</span><span class="p">,</span> <span class="n">stderrs</span><span class="p">,</span> <span class="n">tvalues</span><span class="p">,</span> <span class="n">pvalues</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
    <span class="n">result</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">params_labels</span>
    <span class="n">result</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'coef'</span><span class="p">,</span> <span class="s1">'stderr'</span><span class="p">,</span> <span class="s1">'tvalue'</span><span class="p">,</span> <span class="s1">'pvalue'</span><span class="p">]</span>
    <span class="n">result</span><span class="p">[</span><span class="s1">'stars'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">''</span>
    <span class="n">result</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">result</span><span class="o">.</span><span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">'stars'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'*'</span>
    <span class="n">result</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">result</span><span class="o">.</span><span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">,</span> <span class="s1">'stars'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'**'</span>
    <span class="n">result</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">result</span><span class="o">.</span><span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">,</span> <span class="s1">'stars'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'***'</span>

    <span class="k">return</span> <span class="n">result</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The default behaviour of this function is to apply a Newey-West correction with 3 lags. The statsmodels implementation for the Newey-West estimator should give the same results as the SAS function written by <a href="http://kelley.iu.edu/nstoffma/fe.html">Noah Stoffman</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">fama_macbeth</span><span class="p">(</span><span class="s1">'y ~ x'</span><span class="p">,</span> <span class="s1">'year'</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[16]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
<thead><tr style="text-align: right;">
<th></th>
      <th>coef</th>
      <th>stderr</th>
      <th>tvalue</th>
      <th>pvalue</th>
      <th>stars</th>
    </tr></thead>
<tbody>
<tr>
<th>Intercept</th>
      <td>0.031278</td>
      <td>0.021295</td>
      <td>1.468810</td>
      <td>1.759490e-01</td>
      <td></td>
    </tr>
<tr>
<th>x</th>
      <td>1.035586</td>
      <td>0.025883</td>
      <td>40.010988</td>
      <td>1.893637e-11</td>
      <td>***</td>
    </tr>
</tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It is possible to forgo the Newey-West correction by passing <code>lags=0</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">fama_macbeth</span><span class="p">(</span><span class="s1">'y ~ x'</span><span class="p">,</span> <span class="s1">'year'</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[17]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
<thead><tr style="text-align: right;">
<th></th>
      <th>coef</th>
      <th>stderr</th>
      <th>tvalue</th>
      <th>pvalue</th>
      <th>stars</th>
    </tr></thead>
<tbody>
<tr>
<th>Intercept</th>
      <td>0.031278</td>
      <td>0.023356</td>
      <td>1.339155</td>
      <td>1.805202e-01</td>
      <td></td>
    </tr>
<tr>
<th>x</th>
      <td>1.035586</td>
      <td>0.033342</td>
      <td>31.059889</td>
      <td>8.389156e-212</td>
      <td>***</td>
    </tr>
</tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Newey-West-Adjustment-for-Standard-Errors">Newey-West Adjustment for Standard Errors<a class="anchor-link" href="#Newey-West-Adjustment-for-Standard-Errors">¶</a>
</h3>
<p>The Newey-West adjustment for standard errors is built-in statsmodels with <code>cov_type=HAC</code> and the <code>maxlags</code> argument passed in the <code>cov_kwds</code> parameter. For much more details, see <a href="http://stackoverflow.com/questions/23420454/newey-west-standard-errors-for-ols-in-python">http://stackoverflow.com/questions/23420454/newey-west-standard-errors-for-ols-in-python</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Note: this adjustment doesn't really make sense for our sample dataset, it's just an illustration.</span>
<span class="n">nw_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">'HAC'</span><span class="p">,</span>
                                              <span class="n">cov_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">'maxlags'</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                                              <span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">nw_ols</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[18]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
<th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.208</td> 
</tr>
<tr>
<th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.208</td> 
</tr>
<tr>
<th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   831.8</td> 
</tr>
<tr>
<th>Date:</th>             <td>Tue, 06 Dec 2016</td> <th>  Prob (F-statistic):</th> <td>2.48e-169</td>
</tr>
<tr>
<th>Time:</th>                 <td>16:31:49</td>     <th>  Log-Likelihood:    </th> <td> -10573.</td> 
</tr>
<tr>
<th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>2.115e+04</td>
</tr>
<tr>
<th>Df Residuals:</th>          <td>  4998</td>      <th>  BIC:               </th> <td>2.116e+04</td>
</tr>
<tr>
<th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
<th>Covariance Type:</th>         <td>HAC</td>       <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
<td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
<th>Intercept</th> <td>    0.0297</td> <td>    0.043</td> <td>    0.695</td> <td> 0.487</td> <td>   -0.054     0.113</td>
</tr>
<tr>
<th>x</th>         <td>    1.0348</td> <td>    0.036</td> <td>   28.841</td> <td> 0.000</td> <td>    0.964     1.105</td>
</tr>
</table>
<table class="simpletable">
<tr>
<th>Omnibus:</th>       <td> 4.912</td> <th>  Durbin-Watson:     </th> <td>   1.096</td>
</tr>
<tr>
<th>Prob(Omnibus):</th> <td> 0.086</td> <th>  Jarque-Bera (JB):  </th> <td>   4.862</td>
</tr>
<tr>
<th>Skew:</th>          <td> 0.070</td> <th>  Prob(JB):          </th> <td>  0.0880</td>
</tr>
<tr>
<th>Kurtosis:</th>      <td> 3.063</td> <th>  Cond. No.          </th> <td>    1.01</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Driscoll-Kraay-Standard-Errors">Driscoll-Kraay Standard Errors<a class="anchor-link" href="#Driscoll-Kraay-Standard-Errors">¶</a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">dk_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">'y ~ x'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">'nw-groupsum'</span><span class="p">,</span>
                                              <span class="n">cov_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">'time'</span><span class="p">:</span> <span class="n">df</span><span class="o">.</span><span class="n">year</span><span class="p">,</span>
                                                        <span class="s1">'groups'</span><span class="p">:</span> <span class="n">df</span><span class="o">.</span><span class="n">firmid</span><span class="p">,</span>
                                                        <span class="s1">'maxlags'</span><span class="p">:</span> <span class="mi">5</span><span class="p">},</span>
                                              <span class="n">use_t</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dk_ols</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[19]:</div>


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
<th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.208</td> 
</tr>
<tr>
<th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.208</td> 
</tr>
<tr>
<th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2633.</td> 
</tr>
<tr>
<th>Date:</th>             <td>Tue, 06 Dec 2016</td> <th>  Prob (F-statistic):</th> <td>3.50e-201</td>
</tr>
<tr>
<th>Time:</th>                 <td>16:31:49</td>     <th>  Log-Likelihood:    </th> <td> -10573.</td> 
</tr>
<tr>
<th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>2.115e+04</td>
</tr>
<tr>
<th>Df Residuals:</th>          <td>  4998</td>      <th>  BIC:               </th> <td>2.116e+04</td>
</tr>
<tr>
<th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
<th>Covariance Type:</th>     <td>nw-groupsum</td>   <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
<td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
<th>Intercept</th> <td>    0.0297</td> <td>    0.023</td> <td>    1.301</td> <td> 0.194</td> <td>   -0.015     0.075</td>
</tr>
<tr>
<th>x</th>         <td>    1.0348</td> <td>    0.020</td> <td>   51.317</td> <td> 0.000</td> <td>    0.995     1.074</td>
</tr>
</table>
<table class="simpletable">
<tr>
<th>Omnibus:</th>       <td> 4.912</td> <th>  Durbin-Watson:     </th> <td>   1.096</td>
</tr>
<tr>
<th>Prob(Omnibus):</th> <td> 0.086</td> <th>  Jarque-Bera (JB):  </th> <td>   4.862</td>
</tr>
<tr>
<th>Skew:</th>          <td> 0.070</td> <th>  Prob(JB):          </th> <td>  0.0880</td>
</tr>
<tr>
<th>Kurtosis:</th>      <td> 3.063</td> <th>  Cond. No.          </th> <td>    1.01</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>

    </div>
    
            <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'left', // Change this to 'center' to center equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2018         <a href="mailto:vincent.gregoire@unimelb.edu.au">Vincent Grégoire</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-253287-9', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
